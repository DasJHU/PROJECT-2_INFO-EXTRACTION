# -*- coding: utf-8 -*-
"""CONTRASTIVE SYSTEM 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x52pTP3rAqS5DZmOO4ATDhzin6JqkhR6
"""

import numpy as np
from collections import defaultdict
from scipy.special import logsumexp
import random
import matplotlib.pyplot as plt

# Loading training and test datasets with label mappings
def load_dataset():
    with open('clsp.lblnames', 'r') as f:
        lblnames = [line.strip() for line in f.readlines()[1:]]
    label_map = {label: idx for idx, label in enumerate(lblnames)}

    with open('clsp.trnscr', 'r') as f:
        train_words = [line.strip() for line in f.readlines()[1:]]

    with open('clsp.trnlbls', 'r') as f:
        train_labels = []
        for line in f.readlines()[1:]:
            train_labels.append([label_map[label] for label in line.strip().split()])

    with open('clsp.endpts', 'r') as f:
        endpoints = [tuple(map(int, line.strip().split())) for line in f.readlines()[1:]]

    with open('clsp.devlbls', 'r') as f:
        test_labels = []
        for line in f.readlines()[1:]:
            test_labels.append([label_map[label] for label in line.strip().split()])

    return lblnames, train_words, train_labels, endpoints, test_labels, label_map

class HMM:
    def __init__(self, num_states, is_silence=False):
        self.num_states = num_states
        self.is_silence = is_silence
        self.transitions = np.zeros((num_states, num_states))
        self.emissions = None
        self.null_transitions = {}  # For exit probabilities
        self.exit_prob = 0.25 if is_silence else 0.2

    def initialize(self, unigram_counts, smoothing=1):
        """Initialize HMM parameters exactly as specified"""
        # Initializing transition matrix
        if self.is_silence:
            # SIL model topology
            self.transitions = np.array([
                [0.25, 0.25, 0.25, 0.25, 0.00],
                [0.00, 0.25, 0.25, 0.25, 0.25],
                [0.00, 0.25, 0.25, 0.25, 0.25],
                [0.00, 0.25, 0.25, 0.25, 0.25],
                [0.00, 0.00, 0.00, 0.00, 0.75]
            ])
            self.null_transitions[(self.num_states-1, 'exit')] = 0.25
        else:
            # Letter model left-to-right topology
            self.transitions = np.array([
                [0.8, 0.2, 0.0],
                [0.0, 0.8, 0.2],
                [0.0, 0.0, 0.8]
            ])
            self.null_transitions[(self.num_states-1, 'exit')] = 0.2

        # Initializing emission probabilities
        total = sum(unigram_counts.values()) + 256 * smoothing
        self.emissions = np.ones((self.num_states, 256)) * smoothing / total
        for y in unigram_counts:
            self.emissions[:,y] = (unigram_counts[y] + smoothing) / total
        self.emissions /= self.emissions.sum(axis=1, keepdims=True)

    def copy(self):
        new_hmm = HMM(self.num_states, self.is_silence)
        new_hmm.transitions = self.transitions.copy()
        new_hmm.emissions = self.emissions.copy()
        new_hmm.null_transitions = self.null_transitions.copy()
        return new_hmm

class WordModel:
    def __init__(self, word, letter_models, silence_model):
        self.word = word
        self.letter_models = letter_models
        self.silence_model = silence_model
        self.states = []
        self.transitions = None
        self.emissions = None
        self.null_transitions = {}

    # Contructing composite HMM for word
    def build(self):
        self.states = []
        state_offsets = []

        # Adding initial SIL
        state_offsets.append(len(self.states))
        self.states.extend([('SIL', i) for i in range(self.silence_model.num_states)])

        # Adding letters
        for letter in self.word:
            state_offsets.append(len(self.states))
            self.states.extend([(letter, i) for i in range(self.letter_models[letter].num_states)])

        # Adding final SIL
        state_offsets.append(len(self.states))
        self.states.extend([('SIL', i) for i in range(self.silence_model.num_states)])

        # Initializing transition matrix
        num_states = len(self.states)
        self.transitions = np.zeros((num_states, num_states))

        # Connecting components with null transitions
        prev_offset = 0
        for i, offset in enumerate(state_offsets[1:]):
            if i == 0:
                # Connecting initial SIL to first letter
                for s in range(self.silence_model.num_states):
                    self.null_transitions[(prev_offset+s, offset)] = self.silence_model.exit_prob
            elif i == len(state_offsets)-1:
                # Connecting last letter to final SIL
                last_char = self.word[-1]
                for s in range(self.letter_models[last_char].num_states):
                    self.null_transitions[(prev_offset+s, offset)] = self.letter_models[last_char].exit_prob
            else:
                # Connecting letters
                char = self.word[i-1]
                for s in range(self.letter_models[char].num_states):
                    self.null_transitions[(prev_offset+s, offset)] = self.letter_models[char].exit_prob
            prev_offset = offset

        # Adding internal transitions
        for i, (model_type, state) in enumerate(self.states):
            model = self.silence_model if model_type == 'SIL' else self.letter_models[model_type]
            for j in range(model.num_states):
                if model.transitions[state,j] > 0:
                    self.transitions[i, i+j-state] = model.transitions[state,j]

        # Initializing emissions
        self.emissions = np.zeros((num_states, 256))
        for i, (model_type, state) in enumerate(self.states):
            model = self.silence_model if model_type == 'SIL' else self.letter_models[model_type]
            self.emissions[i] = model.emissions[state]

# Computing forward probabilities in log space to avoid underflow
def forward(obs, model):
    T = len(obs)
    N = model.transitions.shape[0]
    log_alpha = np.zeros((T, N))
    scale = np.zeros(T)

    # Initializating alpha[0]
    log_alpha[0] = np.log(model.emissions[:, obs[0]] + 1e-300)
    scale[0] = logsumexp(log_alpha[0])
    log_alpha[0] -= scale[0]

    # Forward iteration to calculate forward probabilities
    for t in range(1, T):
        for j in range(N):
            log_trans = np.log(model.transitions[:, j] + 1e-300)
            log_alpha[t,j] = logsumexp(log_alpha[t-1] + log_trans)
            log_alpha[t,j] += np.log(model.emissions[j, obs[t]] + 1e-300)

        # Handling null transitions
        changed = True
        while changed:
            changed = False
            for (i,j), prob in model.null_transitions.items():
                new_prob = log_alpha[t,i] + np.log(prob + 1e-300)
                if new_prob > log_alpha[t,j]:
                    log_alpha[t,j] = new_prob
                    changed = True

        scale[t] = logsumexp(log_alpha[t])
        log_alpha[t] -= scale[t]

    return log_alpha, scale

# Computing backward probabilties in log space
def backward(obs, model, scale):
    T = len(obs)
    N = model.transitions.shape[0]
    log_beta = np.zeros((T, N))

    # Initializating beta[0]
    log_beta[-1] = 0.0

    # Backward iteration to calculate beta
    for t in range(T-2, -1, -1):
        for i in range(N):
            log_trans = np.log(model.transitions[i, :] + 1e-300)
            log_emit = np.log(model.emissions[:, obs[t+1]] + 1e-300)
            log_beta[t,i] = logsumexp(log_beta[t+1] + log_trans + log_emit)

        # Handling null transitions
        changed = True
        while changed:
            changed = False
            for (i,j), prob in model.null_transitions.items():
                new_prob = log_beta[t,j] + np.log(prob + 1e-300)
                if new_prob > log_beta[t,i]:
                    log_beta[t,i] = new_prob
                    changed = True

        log_beta[t] -= scale[t+1]

    return log_beta

# Training on full training with held-out and kept data using best model
def train_one_iteration(train_words, train_labels, letter_models, silence_model):
    accum = {}
    for letter in letter_models:
        accum[letter] = {
            'trans': np.zeros_like(letter_models[letter].transitions),
            'emiss': np.zeros_like(letter_models[letter].emissions),
            'null': defaultdict(float)
        }
    accum['SIL'] = {
        'trans': np.zeros_like(silence_model.transitions),
        'emiss': np.zeros_like(silence_model.emissions),
        'null': defaultdict(float)
    }

    total_log_prob = 0
    word_data = defaultdict(list)
    for word, lbls in zip(train_words, train_labels):
        word_data[word].append(lbls)

    for word, lbls_list in word_data.items():
        model = WordModel(word, letter_models, silence_model)
        model.build()

        for lbls in lbls_list:
            la, scale = forward(lbls, model)
            lb = backward(lbls, model, scale)
            total_log_prob += np.sum(scale)

            # Computing posterior
            lg = la + lb
            lg -= logsumexp(lg, axis=1, keepdims=True)
            gamma = np.exp(lg)

            # Accumulating counts
            for t in range(len(lbls)):
                for s, (typ, st) in enumerate(model.states):
                    accum[typ]['emiss'][st, lbls[t]] += gamma[t,s]

            for t in range(len(lbls)-1):
                for s1, (typ1, st1) in enumerate(model.states):
                    for s2, (typ2, st2) in enumerate(model.states):
                        if model.transitions[s1,s2] > 0 and typ1 == typ2:
                            prob = np.exp(
                                la[t,s1] +
                                np.log(model.transitions[s1,s2] + 1e-300) +
                                np.log(model.emissions[s2, lbls[t+1]] + 1e-300) +
                                lb[t+1,s2] -
                                scale[t+1]
                            )
                            accum[typ1]['trans'][st1,st2] += prob

            # Accumulating null transition counts
            for (s1,s2), prob in model.null_transitions.items():
                typ1, st1 = model.states[s1]
                typ2, st2 = model.states[s2]
                if typ1 == typ2:
                    null_prob = np.exp(
                        la[-1,s1] +
                        np.log(prob + 1e-300) +
                        lb[-1,s2] -
                        scale[-1]
                    )
                    accum[typ1]['null'][(st1,st2)] += null_prob

    # Updating models
    for letter in letter_models:
        trans = accum[letter]['trans']
        rowsum = trans.sum(axis=1, keepdims=True)
        rowsum[rowsum == 0] = 1
        letter_models[letter].transitions = trans / rowsum

        emiss = accum[letter]['emiss']
        rowsum = emiss.sum(axis=1, keepdims=True)
        rowsum[rowsum == 0] = 1
        letter_models[letter].emissions = emiss / rowsum

        total_null = sum(accum[letter]['null'].values())
        if total_null > 0:
            for (st1,st2), count in accum[letter]['null'].items():
                if st2 == 'exit':
                    letter_models[letter].null_transitions[(st1,st2)] = count / total_null

    # Updating SIL model
    sil_trans = accum['SIL']['trans']
    rowsum = sil_trans.sum(axis=1, keepdims=True)
    rowsum[rowsum == 0] = 1
    silence_model.transitions = sil_trans / rowsum

    sil_emiss = accum['SIL']['emiss']
    rowsum = sil_emiss.sum(axis=1, keepdims=True)
    rowsum[rowsum == 0] = 1
    silence_model.emissions = sil_emiss / rowsum

    # Updating SIL null transitions
    total_null = sum(accum['SIL']['null'].values())
    if total_null > 0:
        for (st1,st2), count in accum['SIL']['null'].items():
            if st2 == 'exit':
                silence_model.null_transitions[(st1,st2)] = count / total_null

    return total_log_prob

# Splitting training into training and validation at 80-20.
def split_data(train_words, train_labels, test_size=0.2):
    word_data = defaultdict(list)
    for word, lbls in zip(train_words, train_labels):
        word_data[word].append(lbls)

    kept_words, kept_labels = [], []
    heldout_words, heldout_labels = [], []

    # Splitting each word's examples
    for word, examples in word_data.items():
        random.shuffle(examples)
        split_idx = int(len(examples) * (1 - test_size))

        kept_words.extend([word]*split_idx)
        kept_labels.extend(examples[:split_idx])

        heldout_words.extend([word]*(len(examples)-split_idx))
        heldout_labels.extend(examples[split_idx:])

    return kept_words, kept_labels, heldout_words, heldout_labels

# Traing with validation checks on held out data- Initial Phase 1
def train_with_validation(kept_words, kept_labels, heldout_words, heldout_labels,
                         letter_models, silence_model, max_iter=35):
    best_accuracy = -np.inf
    best_models = None
    best_iter = 0
    patience = 2
    no_improve = 0

    vocabulary = list(set(kept_words))

    for iteration in range(max_iter):
        train_one_iteration(kept_words, kept_labels, letter_models, silence_model)

        # Evaluating on held-out set
        results = test(heldout_labels, letter_models, silence_model, vocabulary)
        accuracy = sum(1 for i, res in enumerate(results)
                     if res['word'] == heldout_words[i])/len(results)

        print(f"Iteration {iteration+1}: Held-out accuracy = {accuracy:.4f}")

        # Checking for better accuracy and updating best model
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_models = {k: v.copy() for k,v in letter_models.items()}
            best_models['SIL'] = silence_model.copy()
            best_iter = iteration + 1
            no_improve = 0
        else:
            no_improve += 1
            if no_improve >= patience:
                print(f"Early stopping at iteration {iteration+1}")
                break

    print(f"Best accuracy {best_accuracy:.4f} at iteration {best_iter}")
    return best_iter, best_models

# Evaluating models on test data
def test(test_labels, letter_models, silence_model, vocabulary):
    results = []
    word_models = {word: WordModel(word, letter_models, silence_model) for word in vocabulary}

    for lbls in test_labels:
        scores = []

        for word in vocabulary:
            model = word_models[word]
            model.build()
            try:
                _, scale = forward(lbls, model)
                # Calculating log likelihood, NOTE: i mistakenly wrote per_frame_score. per_frame_score here corresponds to total score.
                total_score = np.sum(scale)
                per_frame_score = total_score
                scores.append((word, per_frame_score))
            except:
                scores.append((word, -np.inf))

        # Normalizing scores to sum to 1
        log_scores = np.array([s for _, s in scores])
        log_sum = logsumexp(log_scores)
        confidences = np.exp(log_scores - log_sum)

        best_idx = np.argmax(log_scores)
        results.append({
            'word': scores[best_idx][0],
            'confidence': confidences[best_idx],
            'per_frame_ll': scores[best_idx][1],
            'top3': sorted(scores, key=lambda x: x[1], reverse=True)[:3]
        })

    return results

def plot_likelihood(likelihoods, filename='training_convergence.png'):
    """Plot training convergence"""
    plt.plot(likelihoods)
    plt.xlabel('Iteration')
    plt.ylabel('Total Log Likelihood')
    plt.title('Training Convergence')
    plt.savefig(filename)
    plt.close()

def save_test_results(results, filename='test_results.txt'):
    """Save test results to file"""
    with open(filename, 'w') as f:
        for i, res in enumerate(results):
            f.write(f"Test {i+1}:\n")
            f.write(f"  Predicted: {res['word']}\n")
            f.write(f"  Confidence: {res['confidence']:.4f}\n")
            f.write("  Top 3 candidates:\n")
            for word, score in res['top3']:
                f.write(f"    {word}: {score:.4f}\n")
            f.write("\n")

def main():
    """Main execution function"""
    # Load data
    lblnames, train_words, train_labels, endpoints, test_labels, label_map = load_dataset()

    # Split data
    kept_words, kept_labels, heldout_words, heldout_labels = split_data(train_words, train_labels)

    # Initialize models with kept data
    letters = list("abcdefghijlmnoprstuvwxy")  # without K, Q, and Z.

    # Compute unigram counts from kept data
    all_labels = [label for seq in kept_labels for label in seq]
    unigram_counts = defaultdict(int)
    for label in all_labels:
        unigram_counts[label] += 1

    # Compute silence counts from kept data
    silence_counts = defaultdict(int)
    for seq, (i,j) in zip(kept_labels, endpoints[:len(kept_labels)]):
        for label in seq[:i+1] + seq[j:]:
            silence_counts[label] += 1

    # Initialize letter models
    letter_models = {letter: HMM(3) for letter in letters}
    for letter in letters:
        letter_models[letter].initialize(unigram_counts)

    # Initialize SIL model
    silence_model = HMM(5, is_silence=True)
    silence_model.initialize(silence_counts)

    # Phase 1: Training with validation (early stopping)
    print("Phase 1: Training with validation")
    n_star, best_models = train_with_validation(
        kept_words, kept_labels, heldout_words, heldout_labels,
        letter_models, silence_model,
        max_iter=35  # Maximum possible iterations
    )

    # Use the best models found during validation
    letter_models = {k: v for k,v in best_models.items() if k != 'SIL'}
    silence_model = best_models['SIL']

    # Phase 2: Final training with full data (1 iteration)
    print("\nPhase 2: Final training (1 iteration)")

    # Reinitialize models with full data counts
    all_labels = [label for seq in train_labels for label in seq]
    unigram_counts = defaultdict(int)
    for label in all_labels:
        unigram_counts[label] += 1

    silence_counts = defaultdict(int)
    for seq, (i,j) in zip(train_labels, endpoints):
        for label in seq[:i+1] + seq[j:]:
            silence_counts[label] += 1

    # Train for exactly 1 iteration (with best model Phase 2)
    log_likelihoods = []
    log_likelihood = train_one_iteration(train_words, train_labels, letter_models, silence_model)
    log_likelihoods.append(log_likelihood)

    plot_likelihood(log_likelihoods)

    # Final evaluation
    print("\nFinal Evaluation:")
    vocabulary = list(set(train_words))
    test_results = test(test_labels, letter_models, silence_model, vocabulary)

    print("\nTest Results:")
    for i, res in enumerate(test_results):
        print(f"\nTest {i+1}:")
        print(f"  Predicted: {res['word']}")
        print(f"  Confidence: {res['confidence']:.3f}")
        print(f"  Per-Frame Log Likelihood: {res['per_frame_ll']:.4f}")
        print("  Top candidate:")
        top_word, top_score = res['top3'][0]  # Get the top prediction
        print(f"    {top_word}: {top_score:.4f}")

if __name__ == "__main__":
    main()